{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-4 데이터가공.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngjae8061/AI_Study/blob/main/3_4_%EB%8D%B0%EC%9D%B4%ED%84%B0%EA%B0%80%EA%B3%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zja5J849zjsr"
      },
      "source": [
        "## PyTorch를 이용한 데이터 가공 예시 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk-1iXHqzdIg"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2vpPVq3zy7U"
      },
      "source": [
        "# 우리가 맞출 데이터\n",
        "x = np.random.uniform(-1.2,2,size=(100))\n",
        "y = 0.1*x**3-0.1*x**2+0.1*np.random.uniform(size=(100))\n",
        "plt.plot(x,y,'o')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uoqXipk0KuK"
      },
      "source": [
        "# train_validation_testset분류\n",
        "data = np.concatenate((x.reshape(-1,1),y.reshape(-1,1)),axis=-1) # x(input)랑 y(target)를 묶음 \n",
        "print(data.shape) # 차원0: 데이터개수, 차원1: (x,y) ---> (100, 2) 2차원 size = 100\n",
        "np.random.shuffle(data) # 데이터 골고루 섞음\n",
        "\n",
        "test_num = int(data.shape[0]*0.1) # data.shape[0] = 100 --> test num 100*10% ---> 10개\n",
        "valid_num = int(data.shape[0]*0.1) # data.shape[0] = 100 --> valid num 100*10% ---> 10개\n",
        "train_num = data.shape[0]-valid_num-test_num # train num ---> 80개\n",
        "\n",
        "train_data = data[:train_num] # 0~80개 까지 (80, 2)\n",
        "valid_data = data[train_num:train_num+valid_num] # 80~90개까지 (10, 2)\n",
        "test_data = data[train_num+valid_num:] # 90~100개까지 (10, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EUrbKN33FWV"
      },
      "source": [
        "plt.plot(train_data[:,0],train_data[:,1],'ro',)\n",
        "plt.plot(valid_data[:,0],valid_data[:,1],'ko')\n",
        "plt.plot(test_data[:,0],test_data[:,1],'go')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iEM6pRG5qNW"
      },
      "source": [
        "# torch batch\n",
        "# 이 함수 형태 유용!\n",
        "class dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,data):\n",
        "    self.data = data\n",
        "    self.x = self.data[:,0].reshape(-1,1) # 첫번째 차원 100 by 1 차원의 행렬로\n",
        "    self.y = self.data[:,1].reshape(-1,1) # 두번째 차원 100 by 1 차원의 행렬로\n",
        "\n",
        "  # 배치사이즈 설정\n",
        "  def __getitem__(self,idx): # (100, 2)에서 batchsize = 3(3개의 랜덤 수를 뽑아내라) -> idx(0, 50, 99)\n",
        "    return torch.Tensor(self.x[idx]),torch.Tensor(np.array(self.y[idx]))\n",
        "  \n",
        "  # 전체 데이터셋이 몇개가 있냐?\n",
        "  def __len__(self):\n",
        "    return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYyVFAZo6fP7"
      },
      "source": [
        "train_dataset = dataset(train_data) # train_data --> (80, 2)   위에 정의한 빨간점을 넣음\n",
        "# DataLoader에는 어떤 데이터셋(train_dataset)이 필요하고 배치사이즈(batch_size=32)가 몇개 필요하고 \n",
        "# 매번 트레이닝 할때마다 섞을거고(shuffle=True) 32개씩 나누고 남은 애들도 버리지 않고 가져갈거다.(drop_last=False)\n",
        "# batch_size=32 이렇게되면 __getitem__()에서 0~80개중 32개의 array로 무작위로 생성\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True,drop_last=False) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoflRHgi6rYb"
      },
      "source": [
        "for X,Y in train_loader:\n",
        "  print(X.shape)\n",
        "  print(Y.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru13MiZV60sM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}