{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3-9 토치그 외 기능.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngjae8061/AI_Study/blob/main/3_9_%ED%86%A0%EC%B9%98%EA%B7%B8_%EC%99%B8_%EA%B8%B0%EB%8A%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeohbAJoOrgv"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOhl8h4ULZuU"
      },
      "source": [
        "## CUDA 하드웨어 가속기 이용법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HunkHKV7bBWW"
      },
      "source": [
        "- 먼저 상단 메뉴에 런타임 - 런타임 유형 변경 - 하드웨어 가속기[GPU]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I00_WvdTLG18"
      },
      "source": [
        "print(torch.cuda.is_available()) # cuda를 사용 가능?\n",
        "\n",
        "print(torch.cuda.current_device()) # cuda 장치의 정체?\n",
        "\n",
        "print(torch.cuda.device_count()) # 그래픽 카드 몇 장?\n",
        "\n",
        "print(torch.cuda.get_device_name(0)) # 그래픽 카드 이름\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 앞으로 torch안의 메모리변수를 어느장치에 할당할지 정의. cuda 사용 가능하면 cuda 그게 아니라면 cpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwk8ZTCAMA5M"
      },
      "source": [
        "## 모델 저장 및 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8WHGNSzLXGG"
      },
      "source": [
        "class model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(model,self).__init__()\n",
        "    self.lin1 = nn.Linear(1,1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = self.lin1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMLwS_p1Qw8Z"
      },
      "source": [
        "test_model = model().to(device) # test_model은 cuda 장치에 할당\n",
        "optimizer = optim.SGD(test_model.parameters(),lr=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMkWQIL5Wqve"
      },
      "source": [
        "x_data = np.linspace(-1,1,100)\n",
        "y_data = np.sin(x_data)+np.random.uniform(-1,1,size=100)\n",
        "x = torch.Tensor(x_data).view(-1,1).to(device) # x 및 y는 cuda 장치에 할당 + torch.Tensor형태 변환\n",
        "y = torch.Tensor(y_data).view(-1,1).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_UvJjD9RQXd"
      },
      "source": [
        "# test_model 학습\n",
        "for ep in range(10):\n",
        "  optimizer.zero_grad()\n",
        "  y_infer = test_model(x)\n",
        "  loss = torch.mean((y_infer-y)**2)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  print(loss.item())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGW6Pb0vRzms"
      },
      "source": [
        "# 현재까지 학습이 다 완료된 상태 세이브\n",
        "torch.save(test_model,'./model_save.pth') # test_model을 저장 \n",
        "\n",
        "del test_model # test_model 삭제"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXR-uz8BSAlm"
      },
      "source": [
        "# 모델 로딩 !!! 주의 저장된 모델에 대한 소스코드의 정보는 앞서서 정의가 되어있어야 합니다!\n",
        "test_model = torch.load('./model_save.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqiqJCvHZ8QP"
      },
      "source": [
        "print(test_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhAMe_2VXX10"
      },
      "source": [
        "## Tensor --> numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WT_jQ3HXPJX"
      },
      "source": [
        "x = torch.Tensor(torch.linspace(-1,1)).view(-1,1).to(device)\n",
        "\n",
        "y_infer = test_model(x)\n",
        "print(y_infer.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO_ryJ52Xi0j"
      },
      "source": [
        "# detach - cuda나 cpu에 연결되있던 유기적인 관계를 해소\n",
        "# cpu - cuda에 있 detach - cuda나 cpu에 연결되있던 유기적인 관계를 해소\n",
        "# cpu - cuda에 있는것을 cpu에 넘겨줌 \n",
        "y_numpy = y_infer.detach().cpu().numpy() \n",
        "print(y_numpy.mean())\n",
        "print(y_numpy.mean())는것을 cpu에 넘겨줌 \n",
        "y_numpy = y_infer.detach().cpu().numpy() \n",
        "print(y_numpy.mean())\n",
        "print(y_numpy.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlxIZVEFXxYN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}